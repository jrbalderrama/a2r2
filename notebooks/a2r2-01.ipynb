{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jrbalderrama/a2r2/blob/main/notebooks/a2r2-01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qOVUmdqyTjY"
   },
   "source": [
    "# RUDI Workshop: Introduction to Privacy-Preserving Data Publishing Techniques\n",
    "\n",
    "Tristan ALLARD & Javier ROJAS BALDERRAMA\n",
    "\n",
    "_Univ Rennes, CNRS, INRIA_\n",
    "  \n",
    "This work is licensed under a [Creative Commons Zero v1.0 Universal License](https://creativecommons.org/publicdomain/zero/1.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "\n",
    "We warmly thank François Bodin and Luc Lesoil for their support on the data and the definition of the use-case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook __ONE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 (STARTER)\n",
    "\n",
    "<a id='step_0'></a>\n",
    "\n",
    "This hands-on tutorial is going to introduce you to the issue of *privacy-preserving personal data publishing*. You are going to follow the implementation of a concrete use-case built from open data from the Rennes Metropole area. The main question of the use-case is to know wether a change in the students schedules at the Beaulieu campus impacts the load of the buses that go through the campus. We will answer to this question based on two datasets : the validations inside the buses that stop close to the campus (with timestamps), and the number of students that terminate a class (with timestamps). Our approach consists in training a predictor that outputs the expected number of validations along the day given the number of students terminating a class along the day. However, using raw buses validations for answering to this question may lead to privacy issues because validations can be highly identifying. After having performed some reidentification attacks, you will use a perturbed version of the buses validations dataset and observe the resulting impact on our ability to answer to the main question of the use-case.\n",
    "\n",
    "We designed this tutorial to be a step-by-step guided tour. You can follow sequentially the \"Step i\" tag inside the titles of the sections. Up to you to follow the sequence proposed or to deviate from it, but be careful when leaving the track, it's wild out there ;)\n",
    "\n",
    "We divided the full journey into three topics:\n",
    "\n",
    "1. The naive version\n",
    "2. Privacy issues\n",
    "3. The protected version\n",
    "\n",
    "For your convenience, there are a dedicated notebook for each topic, **you are currently in Notebook ONE**.\n",
    "\n",
    "The notebooks also include questions. Please take some time to think about them. Trying to answer these questions can also help you to gain a deeper understanding. And we would love reading your answers!\n",
    "\n",
    "Ready?\n",
    "\n",
    "Really??\n",
    "\n",
    "Please run the whole notebook (it does not take long) and **go directly to the [Step 1](#step_1).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmKSCNfpfOQ-"
   },
   "source": [
    "## Step 2 (PREAMBLE): Settings and datasets\n",
    "\n",
    "<a id='step_2'></a>\n",
    "\n",
    "Not too disappointed ? So lets now have a look at the data based on which we trained the model. \n",
    "\n",
    "1. The datasets are downloaded\n",
    "2. The libraries required are imported and global variables are setup\n",
    "3. The raw data are aggregated...\n",
    "4. ... and the results are displayed.\n",
    "5. The datasets are prepared for the training process.\n",
    "\n",
    "> Observe the buses validations dataset (section [Display raw data](#sec_display_raw_data))... Can you imagine any issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzLkzFP3fZm-"
   },
   "source": [
    "\n",
    " ### Download datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_Eju0G4yTjY",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!wget -nv -nc https://zenodo.org/record/5509268/files/buses.parquet\n",
    "!wget -nv -nc https://zenodo.org/record/5519319/files/classes.parquet -O classes_filiere.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4teYxHrfnuh"
   },
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLHjpQH6yTjY"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from atelier import data, io, plot\n",
    "from atelier.extensions.star import preprocessing as sp\n",
    "from atelier.learn import model, preprocessing, validation\n",
    "from atelier.plot import timeline\n",
    "from atelier.utils import time\n",
    "from IPython.display import display\n",
    "from pandas import Timedelta, Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup notebook constants and running environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82e_w9dyyTjY"
   },
   "outputs": [],
   "source": [
    "from atelier.utils import colaboratory\n",
    "\n",
    "# check running environment\n",
    "COLAB_ON = colaboratory.setup()\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kXTLBmBfxuL"
   },
   "source": [
    "### Load and display raw datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQbd6zhNR-j5"
   },
   "source": [
    "#### Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUo9bi14yTk8"
   },
   "outputs": [],
   "source": [
    "# buses dataset\n",
    "buses_path = Path(\"buses.parquet\")\n",
    "buses_dataset = io.read_data(buses_path)\n",
    "\n",
    "# classes dataset\n",
    "classes_path = Path(\"classes_filiere.parquet\")\n",
    "classes_dataset = io.read_data(classes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amAWRS8-RrXl"
   },
   "source": [
    "#### Display raw data\n",
    "\n",
    "<a id='sec_display_raw_data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYS_XqJHR3Kj"
   },
   "source": [
    "**Dataset of buses validations - STAR/Keolis Rennes**\n",
    "\n",
    "Attributes description:\n",
    "\n",
    "- `departure_time`: User's timestamp of bus validation\n",
    "- `stop_name`: Name of the bus stop\n",
    "- `route_short_name`: Number of the bus line\n",
    "- `direction_id`: Code of the bus direction (0 or 'aller', bus from city center/1 or 'retour' bus to city center)\n",
    "- `stop_id`: Code (unique) of the bus stop\n",
    "- `count`: Number of validations\n",
    "- `stop_lat`: GPS latitude coordinate of the bus stop \n",
    "- `stop_lon`: GPS longitude coordinate of the bus stop\n",
    "- `id`: User identifier (unique)\n",
    "\n",
    "```\n",
    "####################\n",
    "# BEGIN : Observe\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(buses_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset of students - Université de Rennes 1, Campus Beaulieu**\n",
    "\n",
    "- `fin_cours`: Timestamp of end of a course\n",
    "- `filiere`: Students background or speciality\n",
    "- `nombre_etudiant`: Number of students by background finishing a course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-H-J9lkbTynD"
   },
   "outputs": [],
   "source": [
    "display(classes_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# END : Observe\n",
    "####################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Food for thoughts\n",
    "\n",
    "```\n",
    "####################\n",
    "# BEGIN : Answer\n",
    "```\n",
    "\n",
    "> 1. Is there any information directly identifying in the raw data?\n",
    "> 2. Could you describe possible auxiliary information that could lead to re-identifications?\n",
    "\n",
    "```\n",
    "# END : Answer\n",
    "####################\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3ZxqVvcSSgF"
   },
   "source": [
    "### Pre-process raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scDTdmHFyTk8"
   },
   "outputs": [],
   "source": [
    "# target bus stops\n",
    "beaulieu_stops = [\n",
    "    \"Les Préales\",\n",
    "    \"Tournebride\",\n",
    "    \"Beaulieu Chimie\",\n",
    "    \"Beaulieu INSA\",\n",
    "    \"Beaulieu Restau U\",\n",
    "]\n",
    "\n",
    "\n",
    "buses_dataset = data.aggregate_dataframe(\n",
    "    buses_dataset,\n",
    "    by=\"departure_time\",\n",
    "    agg={\"count\": \"sum\"},\n",
    "    attribute=\"stop_name\",\n",
    "    value=beaulieu_stops,\n",
    "    keep_index=False,\n",
    ").rename(columns={\"count\": \"validations\"})\n",
    "\n",
    "classes_dataset = classes_dataset.rename(\n",
    "    columns={\n",
    "        \"nombre_etudiant\": \"students\",\n",
    "        \"filiere\": \"background\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZV4MJqgogTB0"
   },
   "source": [
    "### Display agregated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX__8ghegg3F"
   },
   "source": [
    "#### Number of validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33PDn8bpyTk8"
   },
   "outputs": [],
   "source": [
    "display(buses_dataset)\n",
    "timeline.plot(buses_dataset, \"validations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjmGFdCDgpk3"
   },
   "source": [
    "#### Number of students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OP9gJJueyTk8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(classes_dataset)\n",
    "timeline.plot(classes_dataset, \"students\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataset together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMIuDquXyTk8"
   },
   "outputs": [],
   "source": [
    "dataset = data.merge_dataframes(classes_dataset, buses_dataset)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dataset subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_rentree = Timestamp(\"2021-09-06\")\n",
    "la_toussaint = Timestamp(\"2021-11-01\")\n",
    "one_week = Timedelta(7, unit=\"day\")\n",
    "\n",
    "end_train = time.get_next_monday(dataset, weeks=9)\n",
    "start_test = time.get_next_monday(dataset, weeks=10)\n",
    "\n",
    "timeline.plot_with_annotations(\n",
    "    dataset,\n",
    "    attributes=[\"students\", \"validations\"],\n",
    "    delimiters=[(\"val\", end_train), (\"test\", start_test)],\n",
    "    timeframes=[(\"holidays\", la_toussaint, one_week)],\n",
    "    title=\"Counts of Students & Validations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-CFufprhULZ"
   },
   "source": [
    "### Enhance data attributes to create a predictive model based on machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TF56rcALkfO7"
   },
   "source": [
    "#### Improve dataset by mining information from date and time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = pd.date_range(start=la_toussaint, periods=7, freq=\"D\")\n",
    "dataset_with_features = preprocessing.timeline_feature_extraction(dataset, holidays)\n",
    "dataset_with_features.loc[\n",
    "    dataset_with_features[\"background\"] == 0, \"background\"\n",
    "] = \"Empty\"\n",
    "display(dataset_with_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiD_2WATkqsE"
   },
   "source": [
    "#### Split the dataset to train a machine learning tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "melyhYOiACiE"
   },
   "outputs": [],
   "source": [
    "# train - test dataset split\n",
    "train_test_datasets = preprocessing.timeline_train_test_split(\n",
    "    dataset_with_features,\n",
    "    start_test=start_test,\n",
    "    end_train=end_train,\n",
    ")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = train_test_datasets\n",
    "X_train, y_train = data.split_dataframe(train_dataset, target=\"validations\")\n",
    "X_val, y_val = data.split_dataframe(val_dataset, target=\"validations\")\n",
    "X_test, y_test = data.split_dataframe(test_dataset, target=\"validations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5Hiwx5O7gXw"
   },
   "source": [
    "## TOOL: A neural network as a regressor for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxRu24uH8vQM"
   },
   "source": [
    "### Define a neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# BEGIN : play\n",
    "\n",
    "# dimension (neurons) of a hidden layers\n",
    "HIDDEN_LAYER_SIZES = (64, 64, 64)\n",
    "\n",
    "# number of rows processed at the same time\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# max number of iterations during training\n",
    "MAX_ITERATIONS = 256\n",
    "\n",
    "# END : play\n",
    "####################\n",
    "\n",
    "\n",
    "# dataset transformer used by learning model\n",
    "transformer = sp.make_column_transformer()\n",
    "\n",
    "# default regressor is interchangable with others like LinearRegression\n",
    "regressor = model.get_default_regressor(\n",
    "    hidden_layer_sizes=HIDDEN_LAYER_SIZES,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_iterations=MAX_ITERATIONS,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# k corresponds to the number of features to retain after encoding ~80 %\n",
    "regressor_pipeline = model.make_pipeline(\n",
    "    transformer, regressor, k=42, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UORhj0JelLX3"
   },
   "source": [
    "### Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLPRegressor requires a 'np 1d array' for 'y' but not all regressors do it\n",
    "regressor_pipeline.fit(X_train, y_train.to_numpy().ravel())\n",
    "\n",
    "# setup a dataframe with results of training\n",
    "train_results = model.predict_and_compare(regressor_pipeline, X_train, y_train)\n",
    "\n",
    "# show timeline of trainig\n",
    "timeline.plot_with_annotations(\n",
    "    train_results,\n",
    "    attributes=[\"references\", \"predictions\"],\n",
    "    secondary_y=False,\n",
    "    title=\"Training Dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmxvTcwSlaqm"
   },
   "source": [
    "### Show the quality of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a dataframe with results of validation\n",
    "val_results = model.predict_and_compare(regressor_pipeline, X_val, y_val)\n",
    "\n",
    "validation.print_metrics(val_results)\n",
    "plot.residuals_plot(\n",
    "    val_results,\n",
    "    attributes=(\"predictions\", \"residuals\"),\n",
    ")\n",
    "\n",
    "plot.losses_plot(regressor.loss_curve_)\n",
    "print(f\"\\tModel Loss:              {regressor.loss_:.3f}\")\n",
    "print(f\"\\tNumber of Features:      {regressor_pipeline[:-1].transform(X_val).shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Th2MSHU5lrfL"
   },
   "outputs": [],
   "source": [
    "print(f\"predictor model: NN\")\n",
    "nn_results = model.predict_and_compare(regressor_pipeline, X_test, y_test)\n",
    "\n",
    "display(nn_results)\n",
    "timeline.residuals_plot(\n",
    "    nn_results,\n",
    "    attributes=(\"references\", \"predictions\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaQUkM6X8_2s"
   },
   "source": [
    "## Compare the neural network against a baseline method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8nCaMtem6sC"
   },
   "source": [
    " ### Train a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regressor_pipeline = model.make_pipeline(\n",
    "    transformer,\n",
    "    LinearRegression(),\n",
    ")\n",
    "\n",
    "linear_regressor_pipeline.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmawhK9mm_Du"
   },
   "source": [
    "### Show the predictions of the two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "la5JsWUpyTk8"
   },
   "outputs": [],
   "source": [
    "print(\"Baseline model: linear regression\")\n",
    "lr_results = model.predict_and_compare(\n",
    "    linear_regressor_pipeline,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")\n",
    "\n",
    "validation.print_metrics(lr_results)\n",
    "timeline.predictions_interval_plot(\n",
    "    dataset, lr_results, nn_results, names=[\"GT\", \"LN\", \"NN\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tawuGE-n9PTw"
   },
   "source": [
    "## Step 1 (RESULT): Impact of changing students schedules on buses validations\n",
    "\n",
    "<a id='step_1'></a>\n",
    "\n",
    "Lets start with the end. We are going to answer to the question raised\n",
    "by our use case:\n",
    "\n",
    "> Could a change in the time at which students finish have a *significant*\n",
    "> impact on the number of validations in buses ?\n",
    "\n",
    "In order to answer to this question, we have trained above a machine\n",
    "learning model that we are going to use as a predictor *(please wait\n",
    "a little bit for information on the training process)*. Given a time\n",
    "(and possibly a group of students), the model outputs an estimation of\n",
    "the number of buses validations on the campus.\n",
    "\n",
    "You can play with the timeshift below and observe the impact on the \n",
    "validations. Search the following comments:\n",
    "\n",
    "```py\n",
    "####################\n",
    "# BEGIN : ...\n",
    "...\n",
    "# END : ...\n",
    "####################\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# BEGIN : play\n",
    "\n",
    "SHIFT_IN_MINUTES = 15\n",
    "\n",
    "# available backgrounds (None mean do not filter an take 'all' of them):\n",
    "#   ['ISTIC', 'DUT', 'ESIR', 'SVE', 'SPM', 'Math', 'Philo']\n",
    "BACKGROUNDS = [\"Philo\"]\n",
    "\n",
    "# END : play\n",
    "####################\n",
    "\n",
    "# TODO test https://stackoverflow.com/questions/29504252\n",
    "# transformer_weights with union between background and other transformers\n",
    "\n",
    "# reload original classes dataset for time shifting\n",
    "classes_dataset_ = io.read_data(classes_path).rename(\n",
    "    columns={\n",
    "        \"nombre_etudiant\": \"students\",\n",
    "        \"filiere\": \"background\",\n",
    "    }\n",
    ")\n",
    "\n",
    "minutes = Timedelta(SHIFT_IN_MINUTES, unit=\"T\")\n",
    "classes_dataset_ = data.shift_datetime_index(\n",
    "    classes_dataset_,\n",
    "    minutes,\n",
    "    attribute=\"background\",\n",
    "    value=BACKGROUNDS,\n",
    ")\n",
    "\n",
    "dataset_ = data.merge_dataframes(classes_dataset_, buses_dataset)\n",
    "dataset_ = preprocessing.timeline_feature_extraction(dataset_, holidays)\n",
    "dataset_.loc[dataset_[\"background\"] == 0, \"background\"] = \"Empty\"\n",
    "datasets_ = preprocessing.timeline_train_test_split(\n",
    "    dataset_,\n",
    "    start_test=start_test,\n",
    ")\n",
    "\n",
    "_, test_dataset_ = datasets_\n",
    "X_test_, y_test_ = data.split_dataframe(test_dataset_, target=\"validations\")\n",
    "\n",
    "nn_results_ = model.predict_and_compare(\n",
    "    regressor_pipeline,\n",
    "    X_test_,\n",
    "    y_test_,\n",
    ")\n",
    "\n",
    "timeline.predictions_interval_plot_with_staggings(\n",
    "    nn_results,\n",
    "    nn_results_,\n",
    "    names=[\"predictions\", \"staggings\"],\n",
    ")\n",
    "\n",
    "####################\n",
    "# BEGIN : Observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END : Observe\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food for thoughts\n",
    "\n",
    "```\n",
    "####################\n",
    "# BEGIN : Answer\n",
    "```\n",
    "\n",
    "> 1. How can you observe the impact of changing the schedules?\n",
    "> 2. What is the expected impact of shifting the schedules by 15min?\n",
    "> 3. Is the expected impact of a 60 mins shift bigger?\n",
    "> 4. Is there a *small* shift (e.g., less than 60 mins) that would result in a large impact?\n",
    "\n",
    "```\n",
    "# END : Answer\n",
    "####################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now you can go to the [Step 2](#step_2).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDEIVmT4yTk8"
   },
   "source": [
    "# References\n",
    "\n",
    " - https://colab.research.google.com/drive/1enI68fTdPI2w5KKv6jyL0Lcq9Zg3BbLx?usp=sharing"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "NmKSCNfpfOQ-",
    "qzLkzFP3fZm-",
    "O4teYxHrfnuh",
    "-kXTLBmBfxuL",
    "ZV4MJqgogTB0",
    "F-CFufprhULZ",
    "b5Hiwx5O7gXw",
    "tawuGE-n9PTw",
    "s4gBkGhqpaL7"
   ],
   "include_colab_link": true,
   "name": "a2r2-notebook01.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "07e8c18849bc3008fa8e563e061106758a45cf3d8ca88585245492e31e786667"
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit ('venv-a2r2': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
