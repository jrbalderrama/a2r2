{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-",
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.4 64-bit ('venv-a2r2': venv)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.4"
    },
    "colab": {
      "name": "run_nn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NmKSCNfpfOQ-",
        "qzLkzFP3fZm-",
        "O4teYxHrfnuh",
        "-kXTLBmBfxuL",
        "ZV4MJqgogTB0",
        "F-CFufprhULZ",
        "b5Hiwx5O7gXw",
        "tawuGE-n9PTw",
        "s4gBkGhqpaL7"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "d5511370cecfc9f72087461b207d0bd90f18099e89758b2a61eb3e3243f66294"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrbalderrama/a2r2/blob/main/a2r2-02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUDI Workshop: Introduction to Private Private Enhancing Technologies\n",
        "\n",
        "## Notebook __TWO__: The case for privacy\n",
        "\n",
        "Tristan ALLARD & Javier ROJAS BALDERRAMA\n",
        "\n",
        "_Univ Rennes, CNRS, INRIA_\n",
        "  \n",
        "This work is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)"
      ],
      "metadata": {
        "id": "5qOVUmdqyTjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preamble\n",
        "\n",
        "Yes, raw data is not immune to re-identification! \n",
        "\n",
        "You are now going to perform a reidentification attack on a small set of targets. To this end, we will give you some auxiliary information (also called background knowledge) and programming tools for helping you query the dataset. \n",
        "\n",
        "But first lets visualize..."
      ],
      "metadata": {
        "id": "OD991wF88Rio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ### Download dataset\n"
      ],
      "metadata": {
        "id": "qzLkzFP3fZm-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!wget -nv -nc https://zenodo.org/record/5509268/files/buses.parquet"
      ],
      "outputs": [],
      "metadata": {
        "scrolled": false,
        "id": "u_Eju0G4yTjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Required imports and setups"
      ],
      "metadata": {
        "id": "O4teYxHrfnuh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Import libraries\n",
        "import os\n",
        "from errno import ENOENT\n",
        "from pathlib import Path\n",
        "from typing import Optional, Sequence, Tuple\n",
        "\n",
        "import folium\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import pyarrow.parquet as pq\n",
        "from folium.plugins import HeatMapWithTime\n",
        "from IPython import display, get_ipython\n",
        "from numpy import ndarray\n",
        "from pandas import NA, DataFrame, DatetimeIndex, Series, Timedelta, Timestamp"
      ],
      "outputs": [],
      "metadata": {
        "id": "PLHjpQH6yTjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set notebook constants and detect running environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# project base directory\n",
        "BASE_DIRECTORY = Path(\".\")\n",
        "\n",
        "# detect running environment\n",
        "COLAB_ON = True if \"google.colab\" in str(get_ipython()) else False"
      ],
      "outputs": [],
      "metadata": {
        "id": "fToRyDS0yTjY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Set Ploty renderer\n",
        "if COLAB_ON:\n",
        "    pio.renderers.default = \"colab\""
      ],
      "outputs": [],
      "metadata": {
        "id": "82e_w9dyyTjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display raw buses validations dataset"
      ],
      "metadata": {
        "id": "s4gBkGhqpaL7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# load dataset from file system\n",
        "def load_data(\n",
        "    path: Path,\n",
        ") -> DataFrame:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(ENOENT, os.strerror(ENOENT), path)\n",
        "\n",
        "    table = pq.read_table(path)\n",
        "    return table.to_pandas()\n",
        "\n",
        "\n",
        "# show a dataframe as a table\n",
        "def display_dataframe(\n",
        "    dataframe: DataFrame,\n",
        ") -> None:\n",
        "    if COLAB_ON:\n",
        "        from google.colab import data_table\n",
        "\n",
        "        data_table.DataTable(\n",
        "            # 20000 is the max limit to run p\n",
        "            dataframe[:20000],\n",
        "            include_index=False,\n",
        "            num_rows_per_page=20,\n",
        "        )\n",
        "    else:\n",
        "        display.display(dataframe)"
      ],
      "outputs": [],
      "metadata": {
        "id": "iUo9bi14yTk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "filename = \"buses.parquet\"\n",
        "path = BASE_DIRECTORY.joinpath(filename)\n",
        "buses_dataset = load_data(path)\n",
        "display_dataframe(buses_dataset)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# show dataset on a map\n",
        "def plot_heatmap(\n",
        "    dataframe: DataFrame,\n",
        "    group_column: str = \"departure_time\",\n",
        "    # Rennes GPS coordinates\n",
        "    location: Tuple[float, float] = (48.1147, -1.6794),\n",
        ") -> None:\n",
        "    _dataframe = dataframe.copy(deep=True)\n",
        "    timestamps = []\n",
        "    coordinates = []\n",
        "    for timestamp, coordinate in _dataframe.groupby(group_column):\n",
        "        timestamps.append(str(timestamp))\n",
        "        coordinates.append(\n",
        "            coordinate[\n",
        "                [\n",
        "                    \"stop_lat\",\n",
        "                    \"stop_lon\",\n",
        "                ]\n",
        "            ].values.tolist()\n",
        "        )\n",
        "\n",
        "    base_map = folium.Map(\n",
        "        location=location,\n",
        "        zoom_start=11,\n",
        "        tiles=\"https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png\",\n",
        "        # tiles=\"https://{s}.basemaps.cartocdn.com/dark_nolabels/{z}/{x}/{y}{r}.png\",\n",
        "        attr=\"CartoDB\",\n",
        "    )\n",
        "\n",
        "    heat_map = HeatMapWithTime(\n",
        "        data=coordinates,\n",
        "        index=timestamps,\n",
        "        auto_play=True,\n",
        "        min_speed=1,\n",
        "        radius=4,\n",
        "        max_opacity=0.5,\n",
        "    )\n",
        "\n",
        "    heat_map.add_to(base_map)\n",
        "    display.display(base_map)"
      ],
      "outputs": [],
      "metadata": {
        "id": "p-1jePEeyTk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_heatmap(buses_dataset)"
      ],
      "outputs": [],
      "metadata": {
        "id": "KwNpJzamyTk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attacking raw buses validations\n",
        "\n",
        "TODO"
      ],
      "metadata": {
        "id": "65WnAyybppNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explaining the success of the attacks"
      ],
      "metadata": {
        "id": "wgTWdPnapwFd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# drop geospatial attributes from dataset\n",
        "def tidy_dataframe(\n",
        "    dataframe: DataFrame,\n",
        ") -> DataFrame:\n",
        "    dataframe_ = dataframe.copy()\n",
        "    return dataframe_[\n",
        "        [\n",
        "            \"departure_time\",\n",
        "            \"id\",\n",
        "            \"stop_name\",\n",
        "            \"route_short_name\",\n",
        "            \"stop_id\",\n",
        "            \"direction_id\",\n",
        "        ]\n",
        "    ]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shannon's entropy"
      ],
      "metadata": {
        "id": "1OHcTzRI9oQo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# compute the entropy of a serie\n",
        "def entropy(\n",
        "    series: Series,\n",
        "    base: int = 2,\n",
        "    normalize: bool = False,\n",
        ") -> float:\n",
        "    # compute the expectation of a serie\n",
        "    def expectation(probability: Series) -> float:\n",
        "        return (probability * np.log(probability) / np.log(base)).sum()\n",
        "\n",
        "    # compute the efficiency of a serie\n",
        "    def efficiency(entropy: float, length: int) -> float:\n",
        "        return entropy * np.log(base) / np.log(length)\n",
        "\n",
        "    probability = series.value_counts(normalize=True, sort=False)\n",
        "    h = -expectation(probability)\n",
        "    return efficiency(h, series.size) if normalize else h\n",
        "\n",
        "\n",
        "# compute the entropy of a dataframe\n",
        "def get_entropies(\n",
        "    dataframe: DataFrame,\n",
        "    base: int = 2,\n",
        "    normalize: bool = False,\n",
        ") -> Series:\n",
        "    dataframe_ = dataframe.copy()\n",
        "    entropies = dataframe_.apply(\n",
        "        entropy,\n",
        "        base=base,\n",
        "        normalize=normalize,\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        entropies.to_frame()\n",
        "        .reset_index()\n",
        "        .rename(\n",
        "            {\n",
        "                \"index\": \"attribute\",\n",
        "                0: \"entropy\",\n",
        "            },\n",
        "            axis=1,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "# show the entropies as a dataframe as barplot\n",
        "def plot_entropies(\n",
        "    dataframe: DataFrame,\n",
        ") -> None:\n",
        "    figure = px.bar(\n",
        "        dataframe,\n",
        "        x=\"entropy\",\n",
        "        y=\"attribute\",\n",
        "        orientation=\"h\",\n",
        "        color=\"attribute\",\n",
        "    )\n",
        "\n",
        "    figure.update_traces(\n",
        "        texttemplate=\"%{x:.2f}\",\n",
        "        textposition=\"auto\",\n",
        "    )\n",
        "\n",
        "    figure.update_layout(showlegend=False)\n",
        "    figure.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "AS66DfaDyTk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# get a simplified view of the dataset\n",
        "dataset = tidy_dataframe(buses_dataset)\n",
        "\n",
        "# show the dataset\n",
        "display_dataframe(dataset)\n",
        "\n",
        "# compute the entropies of the dataset\n",
        "entropies = get_entropies(dataset, normalize=True)\n",
        "\n",
        "# show a barplot of the entropies \n",
        "plot_entropies(entropies)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ckEdKVZZyTk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anonymity Set"
      ],
      "metadata": {
        "id": "b0bECEV09vVw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# compute the anonymity set of a 'formated' dataframe\n",
        "def get_anonymity_set(\n",
        "    dataframe: DataFrame,\n",
        "    *,\n",
        "    subset: Optional[Sequence[str]] = None,\n",
        "    reindex: bool = False,\n",
        ") -> Series:\n",
        "    # reset index by including zeroes values\n",
        "    def reset_index(serie: Series) -> Series:\n",
        "        domain = range(1, serie.index.max() + 1)\n",
        "        return serie.reindex(domain, fill_value=0)\n",
        "\n",
        "    dataframe_ = dataframe.copy()\n",
        "    multiplicity = dataframe_.value_counts(subset=subset)\n",
        "    aset = multiplicity.value_counts().sort_index()\n",
        "    aset = reset_index(aset) if reindex else aset\n",
        "    return (\n",
        "        aset.to_frame()\n",
        "        .reset_index()\n",
        "        .rename(\n",
        "            {\n",
        "                \"index\": \"cardinality\",\n",
        "                0: \"occurrences\",\n",
        "            },\n",
        "            axis=1,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "# show the anonymity set of a dataframe as a barplot\n",
        "def plot_anonymity_set(\n",
        "    dataframe: DataFrame,\n",
        ") -> None:\n",
        "    figure = px.bar(\n",
        "        dataframe,\n",
        "        x=\"cardinality\",\n",
        "        y=\"occurrences\",\n",
        "        color=\"occurrences\",\n",
        "        color_continuous_scale=\"Bluered\",\n",
        "        # template=\"plotly_white\",\n",
        "        title=\"Anonymity Set\",\n",
        "    )\n",
        "\n",
        "    figure.update_coloraxes(showscale=False)\n",
        "    figure.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "YKBT8XzLyTk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# define a subset of specific attributes to take into account\n",
        "SUBSET = [\n",
        "        \"id\",\n",
        "        \"stop_name\",\n",
        "        \"route_short_name\",\n",
        "    ]"
      ],
      "outputs": [],
      "metadata": {
        "id": "pE25rm9iyTk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# get a simplified view of the dataset\n",
        "dataset = tidy_dataframe(buses_dataset)\n",
        "\n",
        "# compute the anonymity set of the dataset for a some attributes\n",
        "anonymity_set = get_anonymity_set(dataset, subset=SUBSET)\n",
        "\n",
        "# show a barplot of the entropies \n",
        "plot_anonymity_set(anonymity_set)"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}