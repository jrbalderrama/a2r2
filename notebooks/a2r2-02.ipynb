{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jrbalderrama/a2r2/blob/main/a2r2-02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qOVUmdqyTjY"
   },
   "source": [
    "# RUDI Workshop: Introduction to Privacy-Preserving Data Publishing Techniques\n",
    "\n",
    "Tristan ALLARD & Javier ROJAS BALDERRAMA\n",
    "\n",
    "_Univ Rennes, CNRS, INRIA_\n",
    "  \n",
    "This work is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook __TWO__: The case for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OD991wF88Rio"
   },
   "source": [
    "## Preamble\n",
    "\n",
    "Yes, raw data is not immune to re-identification! \n",
    "\n",
    "You are now going to perform a reidentification attack on a small set of targets. To this end, we will give you some auxiliary information (also called background knowledge) and programming tools for helping you query the dataset. \n",
    "1. You can display the buses validations dataset [here](#displayvalid) (do not hesitate to play with the filter, although the number of rows available is very limited). \n",
    "2. You can attack the dataset [here](#attack) (do not be afraid to try!). \n",
    "3. In order to understand better your attacks and/or design other attacks, you can display informative measures about the _identifying power_ of the attributes of the dataset ([Step 2](#explain)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzLkzFP3fZm-"
   },
   "source": [
    "\n",
    " ### Download dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u_Eju0G4yTjY",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!wget -nv -nc https://zenodo.org/record/5509268/files/buses.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4teYxHrfnuh"
   },
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PLHjpQH6yTjY"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyarrow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-63bbd315e3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeatMapWithTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyarrow'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import os\n",
    "from errno import ENOENT\n",
    "from pathlib import Path\n",
    "from typing import Optional, Sequence, Tuple\n",
    "\n",
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import pyarrow.parquet as pq\n",
    "from folium.plugins import HeatMapWithTime\n",
    "from IPython import display, get_ipython\n",
    "from numpy import ndarray\n",
    "from pandas import NA, DataFrame, DatetimeIndex, Series, Timedelta, Timestamp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup notebook constants and running environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fToRyDS0yTjY"
   },
   "outputs": [],
   "source": [
    "# project base directory\n",
    "BASE_DIRECTORY = Path(\".\")\n",
    "\n",
    "# detect running environment\n",
    "COLAB_ON = True if \"google.colab\" in str(get_ipython()) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82e_w9dyyTjY"
   },
   "outputs": [],
   "source": [
    "# Set Ploty renderer\n",
    "if COLAB_ON:\n",
    "    pio.renderers.default = \"colab\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4gBkGhqpaL7"
   },
   "source": [
    "### Load and display raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUo9bi14yTk8"
   },
   "outputs": [],
   "source": [
    "# load dataset from file system\n",
    "def load_data(\n",
    "    path: Path,\n",
    ") -> DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(ENOENT, os.strerror(ENOENT), path)\n",
    "\n",
    "    table = pq.read_table(path)\n",
    "    return table.to_pandas()\n",
    "\n",
    "\n",
    "# show a dataframe as a table\n",
    "def display_dataframe(\n",
    "        dataframe: DataFrame,\n",
    ") -> None:    \n",
    "    if COLAB_ON:\n",
    "        spec = importlib.util.find_spec(\"google.colab\")\n",
    "        if spec:            \n",
    "            data_table = importlib.import_module(\"google.colab.data_table\")            \n",
    "            enable_dataframe_formatter = getattr(\n",
    "                data_table, \n",
    "                \"enable_dataframe_formatter\",\n",
    "            )            \n",
    "            \n",
    "            enable_dataframe_formatter()            \n",
    "           \n",
    "    display.display(dataframe[:20000] if COLAB_ON else dataframe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = BASE_DIRECTORY.joinpath(\"buses.parquet\")\n",
    "buses_dataset = load_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='displayvalid'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# BEGIN : Observe\n",
    "\n",
    "display_dataframe(buses_dataset)\n",
    "\n",
    "# END : Observe\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-1jePEeyTk8"
   },
   "outputs": [],
   "source": [
    "# show dataset on a map\n",
    "def plot_heatmap(\n",
    "    dataframe: DataFrame,\n",
    "    group_column: str = \"departure_time\",\n",
    "    # Rennes GPS coordinates\n",
    "    location: Tuple[float, float] = (48.1147, -1.6794),\n",
    ") -> None:\n",
    "    _dataframe = dataframe.copy(deep=True)\n",
    "    timestamps = []\n",
    "    coordinates = []\n",
    "    for timestamp, coordinate in _dataframe.groupby(group_column):\n",
    "        timestamps.append(str(timestamp))\n",
    "        coordinates.append(\n",
    "            coordinate[\n",
    "                [\n",
    "                    \"stop_lat\",\n",
    "                    \"stop_lon\",\n",
    "                ]\n",
    "            ].values.tolist()\n",
    "        )\n",
    "\n",
    "    base_map = folium.Map(\n",
    "        location=location,\n",
    "        zoom_start=11,\n",
    "        tiles=\"https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png\",\n",
    "        # tiles=\"https://{s}.basemaps.cartocdn.com/dark_nolabels/{z}/{x}/{y}{r}.png\",\n",
    "        attr=\"CartoDB\",\n",
    "    )\n",
    "\n",
    "    heat_map = HeatMapWithTime(\n",
    "        data=coordinates,\n",
    "        index=timestamps,\n",
    "        auto_play=True,\n",
    "        min_speed=1,\n",
    "        radius=4,\n",
    "        max_opacity=0.5,\n",
    "    )\n",
    "\n",
    "    heat_map.add_to(base_map)\n",
    "    display.display(base_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "> Showing the heat map of the buses validation only works on a local\n",
    "> Jupyter server (perhaps a *colab* feature/limitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwNpJzamyTk8"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# BEGIN : Observe\n",
    "\n",
    "plot_heatmap(buses_dataset)\n",
    "\n",
    "# END : Observe\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65WnAyybppNH"
   },
   "source": [
    "## Step 1: Attack raw buses validations\n",
    "<a id=\"attack\"></a>\n",
    "\n",
    "Re-identification attacks are simple conceptually. They consist in selecting the subset of individuals whose records match the auxiliary information that the attacker has about them. If a single individual matches the adversarial knowledge, the success of the attack is clear (assuming that the adversarial knowledge is reliable). But when more than a single individual match the adversarial knowledge, is it a failure ? \n",
    "\n",
    "Food for thoughts: \n",
    "- Here is below auxiliary information that you have on different targets. Can you re-identify them ? \n",
    "    - Target 1: \n",
    "    - Target 2: \n",
    "    - Target 3: \n",
    "- By \"looking\" at the dataset (see above), could you imagine stronger auxiliary information ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# BEGIN : Play\n",
    "\n",
    "TODO\n",
    "\n",
    "# END : Play\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgTWdPnapwFd"
   },
   "source": [
    "## Step 2: Explain the success of the attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"explain\"></a>\n",
    "\n",
    "The success of a re-identification attack depends on the identifying power of the attributes that have been used for the attack. You can display below two measures: the [Shannon entropy](#shannon) (that quantifies the amount of information carried by each attribute) and the distribution of the [cardinalities of the anonymity sets](#aset) (that indicates how much individuals are distinguishable on a given set of attributes). Do not hesitate to play with anonymity sets by changing the set of attributes on which the anonymity sets are computed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop geospatial attributes from dataset\n",
    "def tidy_dataframe(\n",
    "    dataframe: DataFrame,\n",
    ") -> DataFrame:\n",
    "    dataframe_ = dataframe.copy()\n",
    "    return dataframe_[\n",
    "        [\n",
    "            \"departure_time\",\n",
    "            \"id\",\n",
    "            \"stop_name\",\n",
    "            \"route_short_name\",\n",
    "            \"stop_id\",\n",
    "            \"direction_id\",\n",
    "        ]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OHcTzRI9oQo"
   },
   "source": [
    "### Shannon's entropy\n",
    "<a id=\"shannon\"></a>\n",
    "\n",
    "TODO texte Shannon \n",
    "\n",
    "Food for thought : \n",
    "- Which attributes give the most information ?\n",
    "- Would your attacks have have been more successful with other/additional information ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AS66DfaDyTk8"
   },
   "outputs": [],
   "source": [
    "# compute the entropy of a serie\n",
    "def entropy(\n",
    "    series: Series,\n",
    "    base: int = 2,\n",
    "    normalize: bool = False,\n",
    ") -> float:\n",
    "    # compute the expectation of a serie\n",
    "    def expectation(probability: Series) -> float:\n",
    "        return (probability * np.log(probability) / np.log(base)).sum()\n",
    "\n",
    "    # compute the efficiency of a serie\n",
    "    def efficiency(entropy: float, length: int) -> float:\n",
    "        return entropy * np.log(base) / np.log(length)\n",
    "\n",
    "    probability = series.value_counts(normalize=True, sort=False)\n",
    "    h = -expectation(probability)\n",
    "    return efficiency(h, series.size) if normalize else h\n",
    "\n",
    "\n",
    "# compute the entropy of a dataframe\n",
    "def get_entropies(\n",
    "    dataframe: DataFrame,\n",
    "    base: int = 2,\n",
    "    normalize: bool = False,\n",
    ") -> Series:\n",
    "    dataframe_ = dataframe.copy()\n",
    "    entropies = dataframe_.apply(\n",
    "        entropy,\n",
    "        base=base,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        entropies.to_frame()\n",
    "        .reset_index()\n",
    "        .rename(\n",
    "            {\n",
    "                \"index\": \"attribute\",\n",
    "                0: \"entropy\",\n",
    "            },\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# show the entropies as a dataframe as barplot\n",
    "def plot_entropies(\n",
    "    dataframe: DataFrame,\n",
    ") -> None:\n",
    "    figure = px.bar(\n",
    "        dataframe,\n",
    "        x=\"entropy\",\n",
    "        y=\"attribute\",\n",
    "        orientation=\"h\",\n",
    "        color=\"attribute\",\n",
    "    )\n",
    "\n",
    "    figure.update_traces(\n",
    "        texttemplate=\"%{x:.2f}\",\n",
    "        textposition=\"auto\",\n",
    "    )\n",
    "\n",
    "    figure.update_layout(showlegend=False)\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckEdKVZZyTk8"
   },
   "outputs": [],
   "source": [
    "# get a simplified view of the dataset\n",
    "dataset = tidy_dataframe(buses_dataset)\n",
    "\n",
    "#Â show the dataset\n",
    "display_dataframe(dataset)\n",
    "\n",
    "# compute the entropies of the dataset\n",
    "entropies = get_entropies(dataset, normalize=True)\n",
    "\n",
    "# show a barplot of the entropies \n",
    "plot_entropies(entropies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0bECEV09vVw"
   },
   "source": [
    "### Anonymity Sets\n",
    "<a id=\"aset\"></a>\n",
    "\n",
    "Displaying the cardinalities of the anonymity sets inform about the _re-identifyiability_ of the individuals in the dataset: anonymity sets that have a cardinality equal to 1 contain a single individual, those equal to 2 contain two individuals, _etc_. Selecting the attributes on which you want to compute the anonymity sets and displaying the resulting cardinalities can thus help you explain the success of your attack. An attacker could also tune the attack by using the most identifying attributes. \n",
    "\n",
    "You can chose [below](#asetplay) the attributes on which you compute the anonymity sets. \n",
    "\n",
    "Food for thought : \n",
    "- Which set of attributes is the most identifying ? Can you find it efficiently ?\n",
    "- Would your attacks have have been more successful with other/additional information ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKBT8XzLyTk8"
   },
   "outputs": [],
   "source": [
    "# compute the anonymity set of a 'formated' dataframe\n",
    "def get_anonymity_set(\n",
    "    dataframe: DataFrame,\n",
    "    *,\n",
    "    subset: Optional[Sequence[str]] = None,\n",
    "    reindex: bool = False,\n",
    ") -> Series:\n",
    "    # reset index by including zeroes values\n",
    "    def reset_index(serie: Series) -> Series:\n",
    "        domain = range(1, serie.index.max() + 1)\n",
    "        return serie.reindex(domain, fill_value=0)\n",
    "\n",
    "    dataframe_ = dataframe.copy()\n",
    "    multiplicity = dataframe_.value_counts(subset=subset)\n",
    "    aset = multiplicity.value_counts().sort_index()\n",
    "    aset = reset_index(aset) if reindex else aset\n",
    "    return (\n",
    "        aset.to_frame()\n",
    "        .reset_index()\n",
    "        .rename(\n",
    "            {\n",
    "                \"index\": \"cardinality\",\n",
    "                0: \"occurrences\",\n",
    "            },\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# show the anonymity set of a dataframe as a barplot\n",
    "def plot_anonymity_set(\n",
    "    dataframe: DataFrame,\n",
    ") -> None:\n",
    "    figure = px.bar(\n",
    "        dataframe,\n",
    "        x=\"cardinality\",\n",
    "        y=\"occurrences\",\n",
    "        color=\"occurrences\",\n",
    "        color_continuous_scale=\"Bluered\",\n",
    "        # template=\"plotly_white\",\n",
    "        title=\"Anonymity Set\",\n",
    "    )\n",
    "\n",
    "    figure.update_coloraxes(showscale=False)\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"asetplay\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pE25rm9iyTk8"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# BEGIN : Play\n",
    "\n",
    "# define a subset of specific attributes to take into account\n",
    "SUBSET = [\n",
    "        \"id\",\n",
    "        \"stop_name\",\n",
    "        #\"route_short_name\",\n",
    "    ]\n",
    "\n",
    "# END : Play\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a simplified view of the dataset\n",
    "dataset = tidy_dataframe(buses_dataset)\n",
    "\n",
    "# compute the anonymity set of the dataset for a some attributes\n",
    "anonymity_set = get_anonymity_set(dataset, subset=SUBSET)\n",
    "\n",
    "# show a barplot of the entropies \n",
    "plot_anonymity_set(anonymity_set)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "NmKSCNfpfOQ-",
    "qzLkzFP3fZm-",
    "O4teYxHrfnuh",
    "-kXTLBmBfxuL",
    "ZV4MJqgogTB0",
    "F-CFufprhULZ",
    "b5Hiwx5O7gXw",
    "tawuGE-n9PTw",
    "s4gBkGhqpaL7"
   ],
   "include_colab_link": true,
   "name": "run_nn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "d5511370cecfc9f72087461b207d0bd90f18099e89758b2a61eb3e3243f66294"
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
