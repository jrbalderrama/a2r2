{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-",
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.4 64-bit ('venv-a2r2': venv)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.4"
    },
    "colab": {
      "name": "run_nn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NmKSCNfpfOQ-",
        "qzLkzFP3fZm-",
        "O4teYxHrfnuh",
        "-kXTLBmBfxuL",
        "ZV4MJqgogTB0",
        "F-CFufprhULZ",
        "b5Hiwx5O7gXw",
        "tawuGE-n9PTw",
        "s4gBkGhqpaL7"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "d5511370cecfc9f72087461b207d0bd90f18099e89758b2a61eb3e3243f66294"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrbalderrama/a2r2/blob/main/a2r2-02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUDI Workshop: Introduction to Privacy-Preserving Data Publishing Techniques\n",
        "\n",
        "Tristan ALLARD & Javier ROJAS BALDERRAMA\n",
        "\n",
        "_Univ Rennes, CNRS, INRIA_\n",
        "  \n",
        "This work is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)"
      ],
      "metadata": {
        "id": "5qOVUmdqyTjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook __TWO__: The case for privacy"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preamble\n",
        "\n",
        "Yes, raw data is not immune to re-identification! \n",
        "\n",
        "You are now going to perform a reidentification attack on a small set of targets. To this end, we will give you some auxiliary information (also called background knowledge) and programming tools for helping you query the dataset. \n",
        "\n",
        "But first lets visualize..."
      ],
      "metadata": {
        "id": "OD991wF88Rio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ### Download dataset\n"
      ],
      "metadata": {
        "id": "qzLkzFP3fZm-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!wget -nv -nc https://zenodo.org/record/5509268/files/buses.parquet"
      ],
      "outputs": [],
      "metadata": {
        "scrolled": false,
        "id": "u_Eju0G4yTjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required modules"
      ],
      "metadata": {
        "id": "O4teYxHrfnuh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import importlib\n",
        "import os\n",
        "from errno import ENOENT\n",
        "from pathlib import Path\n",
        "from typing import Optional, Sequence, Tuple\n",
        "\n",
        "import folium\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import pyarrow.parquet as pq\n",
        "from folium.plugins import HeatMapWithTime\n",
        "from IPython import display, get_ipython\n",
        "from numpy import ndarray\n",
        "from pandas import NA, DataFrame, DatetimeIndex, Series, Timedelta, Timestamp\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "PLHjpQH6yTjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup notebook constants and running environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# project base directory\n",
        "BASE_DIRECTORY = Path(\".\")\n",
        "\n",
        "# detect running environment\n",
        "COLAB_ON = True if \"google.colab\" in str(get_ipython()) else False"
      ],
      "outputs": [],
      "metadata": {
        "id": "fToRyDS0yTjY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Set Ploty renderer\n",
        "if COLAB_ON:\n",
        "    pio.renderers.default = \"colab\""
      ],
      "outputs": [],
      "metadata": {
        "id": "82e_w9dyyTjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and display raw dataset"
      ],
      "metadata": {
        "id": "s4gBkGhqpaL7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# load dataset from file system\n",
        "def load_data(\n",
        "    path: Path,\n",
        ") -> DataFrame:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(ENOENT, os.strerror(ENOENT), path)\n",
        "\n",
        "    table = pq.read_table(path)\n",
        "    return table.to_pandas()\n",
        "\n",
        "\n",
        "# show a dataframe as a table\n",
        "def display_dataframe(\n",
        "        dataframe: DataFrame,\n",
        ") -> None:    \n",
        "    if COLAB_ON:\n",
        "        spec = importlib.util.find_spec(\"google.colab\")\n",
        "        if spec:            \n",
        "            data_table = importlib.import_module(\"google.colab.data_table\")            \n",
        "            enable_dataframe_formatter = getattr(\n",
        "                data_table, \n",
        "                \"enable_dataframe_formatter\",\n",
        "            )            \n",
        "            \n",
        "            enable_dataframe_formatter()            \n",
        "           \n",
        "    display.display(dataframe[:20000] if COLAB_ON else dataframe) "
      ],
      "outputs": [],
      "metadata": {
        "id": "iUo9bi14yTk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "path = BASE_DIRECTORY.joinpath(\"buses.parquet\")\n",
        "buses_dataset = load_data(path)\n",
        "display_dataframe(buses_dataset)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# show dataset on a map\n",
        "def plot_heatmap(\n",
        "    dataframe: DataFrame,\n",
        "    group_column: str = \"departure_time\",\n",
        "    # Rennes GPS coordinates\n",
        "    location: Tuple[float, float] = (48.1147, -1.6794),\n",
        ") -> None:\n",
        "    _dataframe = dataframe.copy(deep=True)\n",
        "    timestamps = []\n",
        "    coordinates = []\n",
        "    for timestamp, coordinate in _dataframe.groupby(group_column):\n",
        "        timestamps.append(str(timestamp))\n",
        "        coordinates.append(\n",
        "            coordinate[\n",
        "                [\n",
        "                    \"stop_lat\",\n",
        "                    \"stop_lon\",\n",
        "                ]\n",
        "            ].values.tolist()\n",
        "        )\n",
        "\n",
        "    base_map = folium.Map(\n",
        "        location=location,\n",
        "        zoom_start=11,\n",
        "        tiles=\"https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png\",\n",
        "        # tiles=\"https://{s}.basemaps.cartocdn.com/dark_nolabels/{z}/{x}/{y}{r}.png\",\n",
        "        attr=\"CartoDB\",\n",
        "    )\n",
        "\n",
        "    heat_map = HeatMapWithTime(\n",
        "        data=coordinates,\n",
        "        index=timestamps,\n",
        "        auto_play=True,\n",
        "        min_speed=1,\n",
        "        radius=4,\n",
        "        max_opacity=0.5,\n",
        "    )\n",
        "\n",
        "    heat_map.add_to(base_map)\n",
        "    display.display(base_map)"
      ],
      "outputs": [],
      "metadata": {
        "id": "p-1jePEeyTk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "\n",
        "> Showing the heat map of the buses validation only works on a local\n",
        "> Jupyter server (perhaps a *colab* feature/limitation)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_heatmap(buses_dataset)"
      ],
      "outputs": [],
      "metadata": {
        "id": "KwNpJzamyTk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack raw buses validations\n",
        "\n",
        "TODO"
      ],
      "metadata": {
        "id": "65WnAyybppNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explain the success of the attacks"
      ],
      "metadata": {
        "id": "wgTWdPnapwFd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# drop geospatial attributes from dataset\n",
        "def tidy_dataframe(\n",
        "    dataframe: DataFrame,\n",
        ") -> DataFrame:\n",
        "    dataframe_ = dataframe.copy()\n",
        "    return dataframe_[\n",
        "        [\n",
        "            \"departure_time\",\n",
        "            \"id\",\n",
        "            \"stop_name\",\n",
        "            \"route_short_name\",\n",
        "            \"stop_id\",\n",
        "            \"direction_id\",\n",
        "        ]\n",
        "    ]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shannon's entropy"
      ],
      "metadata": {
        "id": "1OHcTzRI9oQo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# compute the entropy of a serie\n",
        "def entropy(\n",
        "    series: Series,\n",
        "    base: int = 2,\n",
        "    normalize: bool = False,\n",
        ") -> float:\n",
        "    # compute the expectation of a serie\n",
        "    def expectation(probability: Series) -> float:\n",
        "        return (probability * np.log(probability) / np.log(base)).sum()\n",
        "\n",
        "    # compute the efficiency of a serie\n",
        "    def efficiency(entropy: float, length: int) -> float:\n",
        "        return entropy * np.log(base) / np.log(length)\n",
        "\n",
        "    probability = series.value_counts(normalize=True, sort=False)\n",
        "    h = -expectation(probability)\n",
        "    return efficiency(h, series.size) if normalize else h\n",
        "\n",
        "\n",
        "# compute the entropy of a dataframe\n",
        "def get_entropies(\n",
        "    dataframe: DataFrame,\n",
        "    base: int = 2,\n",
        "    normalize: bool = False,\n",
        ") -> Series:\n",
        "    dataframe_ = dataframe.copy()\n",
        "    entropies = dataframe_.apply(\n",
        "        entropy,\n",
        "        base=base,\n",
        "        normalize=normalize,\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        entropies.to_frame()\n",
        "        .reset_index()\n",
        "        .rename(\n",
        "            {\n",
        "                \"index\": \"attribute\",\n",
        "                0: \"entropy\",\n",
        "            },\n",
        "            axis=1,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "# show the entropies as a dataframe as barplot\n",
        "def plot_entropies(\n",
        "    dataframe: DataFrame,\n",
        ") -> None:\n",
        "    figure = px.bar(\n",
        "        dataframe,\n",
        "        x=\"entropy\",\n",
        "        y=\"attribute\",\n",
        "        orientation=\"h\",\n",
        "        color=\"attribute\",\n",
        "    )\n",
        "\n",
        "    figure.update_traces(\n",
        "        texttemplate=\"%{x:.2f}\",\n",
        "        textposition=\"auto\",\n",
        "    )\n",
        "\n",
        "    figure.update_layout(showlegend=False)\n",
        "    figure.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "AS66DfaDyTk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# get a simplified view of the dataset\n",
        "dataset = tidy_dataframe(buses_dataset)\n",
        "\n",
        "#Â show the dataset\n",
        "display_dataframe(dataset)\n",
        "\n",
        "# compute the entropies of the dataset\n",
        "entropies = get_entropies(dataset, normalize=True)\n",
        "\n",
        "# show a barplot of the entropies \n",
        "plot_entropies(entropies)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ckEdKVZZyTk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anonymity Set"
      ],
      "metadata": {
        "id": "b0bECEV09vVw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# compute the anonymity set of a 'formated' dataframe\n",
        "def get_anonymity_set(\n",
        "    dataframe: DataFrame,\n",
        "    *,\n",
        "    subset: Optional[Sequence[str]] = None,\n",
        "    reindex: bool = False,\n",
        ") -> Series:\n",
        "    # reset index by including zeroes values\n",
        "    def reset_index(serie: Series) -> Series:\n",
        "        domain = range(1, serie.index.max() + 1)\n",
        "        return serie.reindex(domain, fill_value=0)\n",
        "\n",
        "    dataframe_ = dataframe.copy()\n",
        "    multiplicity = dataframe_.value_counts(subset=subset)\n",
        "    aset = multiplicity.value_counts().sort_index()\n",
        "    aset = reset_index(aset) if reindex else aset\n",
        "    return (\n",
        "        aset.to_frame()\n",
        "        .reset_index()\n",
        "        .rename(\n",
        "            {\n",
        "                \"index\": \"cardinality\",\n",
        "                0: \"occurrences\",\n",
        "            },\n",
        "            axis=1,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "# show the anonymity set of a dataframe as a barplot\n",
        "def plot_anonymity_set(\n",
        "    dataframe: DataFrame,\n",
        ") -> None:\n",
        "    figure = px.bar(\n",
        "        dataframe,\n",
        "        x=\"cardinality\",\n",
        "        y=\"occurrences\",\n",
        "        color=\"occurrences\",\n",
        "        color_continuous_scale=\"Bluered\",\n",
        "        # template=\"plotly_white\",\n",
        "        title=\"Anonymity Set\",\n",
        "    )\n",
        "\n",
        "    figure.update_coloraxes(showscale=False)\n",
        "    figure.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "YKBT8XzLyTk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# define a subset of specific attributes to take into account\n",
        "SUBSET = [\n",
        "        \"id\",\n",
        "        \"stop_name\",\n",
        "        #\"route_short_name\",\n",
        "    ]"
      ],
      "outputs": [],
      "metadata": {
        "id": "pE25rm9iyTk8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# get a simplified view of the dataset\n",
        "dataset = tidy_dataframe(buses_dataset)\n",
        "\n",
        "# compute the anonymity set of the dataset for a some attributes\n",
        "anonymity_set = get_anonymity_set(dataset, subset=SUBSET)\n",
        "\n",
        "# show a barplot of the entropies \n",
        "plot_anonymity_set(anonymity_set)"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}